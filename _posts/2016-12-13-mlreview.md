---
title: "机器学习复习1-Perceptron"
tags:
  - SVM
  - 机器学习复习
---

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

# 写在开始

由于近期事情较多，期末考试也只剩下两个月，从今天起，开始逐步复习各个科目，每天1-2章。

## 感知机模型

### 基本思想

感知机模型只要针对于二分类，且需要数据是线性可分的，对应的函数为$$f(x)=sign(\omega x+b)$$。其中$$\omega\in \mathbb{R}^n$$作为权值。从中可以看出感知的基本思想在于找到一个超平面（线性性的体现）以期能够将数据分为两类。

### 学习方法

感知机的学习方法是基于误分类的点进行的。由模型可得，若出现误分类，则有$$y_i\cdot(\omega x_i+b)<0$$，感知机的目标即在于：
\\[\min_{\omega,b}{-\sum_{x_i\in M}{y_i(\omega x_i+b)}}\\]
其中$$M$$代表误分类的点的集合。权值更新方式利用随机梯度下降法，即随机取一个误分类点$$(x_i,y_i)$$通过求导对$$(\omega,b)$$进行更新：
\\[\omega=\omega+\eta y_i x_i\\]
\\[b=b+\eta y_i\\]


### 算法的收敛性

假设数据集$$X=\{x_1,x_2,\cdots,x_N\}$$，二元目标集$$T=\{t_1,t_2,\cdots,t_N\}$$，线性可分。则利用感知机学习算法会在有限步内停止。

证明：首先将$$\omega x+b$$简写为$$\omega x$$，又由于样本线性可分，假设所求权值向量为$$\omega^{opt}$$（$$\|\|\omega^{opt}\|\|=1,\omega^{opt}x_i>\delta>0,\forall i$$）。

再对所有样本$$x_i$$归一化，使得$$||x_i||=1$$，且对$$t_i=-1$$的样本考虑$$-x_i$$，即所有样本的目标值均为+1。

设权向量学习序列为$$\omega(0),\omega(1),\cdots,\omega(k),\cdots$$，则：

\\[\omega(k+1)=\omega(k)+\eta(t_k-y_k)x_k=\omega(k)+2\eta x_k=\omega(k)+ux_k\\]

此处只考虑实质性学习。

设$$c(k)=\frac{\omega^{opt}\cdot\omega(k)}{||\omega^{opt}||||\omega(k)||}=\frac{\omega^{opt}\omega(k)}{||\omega(k)||}$$

\\[\omega^{opt}\omega(k+1)=\omega^{opt}(\omega(k)+ux_k)\geq \omega^{opt}\omega(k)+u\delta \geq \omega^{opt}\omega(0)+(k+1)u\delta\geq (k+1)\delta\\]

又有

\\[||\omega(k+1)||^2=||\omega(k)+ux_k||^2=||\omega(k)||^2+2u\omega(k)x_k+u^2||x(k)||^2\leq ||\omega(k)||^2+u^2\leq ||\omega(0)||^2+(k+1)u^2\leq 1+(k+1)u^2\\]

由$$c(k)\leq 1$$可得$$\frac{ku\delta}{\sqrt{1+ku^2}}\leq 1$$

即$$u^2(k^2\delta^2-k)\leq 1$$

即可得到$$k\leq \frac{\sqrt{1+\frac{u^2}{4\delta^2}}}{u\delta}+\frac{1}{2\delta^2}$$

证毕。

### 感知机学习算法的对偶形式

设$$(\omega_0,b_0)=(0,0)$$，则可以看出$$\omega=\sum_{i=1}^{N}{\alpha_iy_ix_i},b=\sum_{i=1}^{N}{\alpha_iy_i}$$，$$\alpha_i$$是第i个数据点在训练中被误分类的次数乘上学习率$$\eta$$。由此可以得到其对偶形式的算法：

 1.$$\alpha_i=0,b=0$$
 2.从数据集中选取$$(x_i,y_i)$$
 3.若$$y_i(\sum_{j=1}^{N}{\alpha_jy_jx_j x_i+b})\leq 0$$，则$$\alpha_i=\alpha_i+\eta,b=b+\eta y_i$$
 4.转回2直至无误分类点

